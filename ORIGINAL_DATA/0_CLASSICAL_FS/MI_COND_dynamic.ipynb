{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0b9f5e-b00c-4bb5-a2ee-0a3464184af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "from numpy import log\n",
    "from scipy.special import digamma\n",
    "from sklearn.neighbors import BallTree, KDTree\n",
    "import sklearn\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "#%% Cargo los datos\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff2a5e0-c002-43e0-8243-21a2a1b10aab",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5555ae1e-44e4-408a-92b2-e3eadb1f75fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCRETE ESTIMATORS\n",
    "def entropyd(sx, base=2):\n",
    "    \"\"\" Discrete entropy estimator\n",
    "        sx is a list of samples\n",
    "    \"\"\"\n",
    "    unique, count = np.unique(sx, return_counts=True, axis=0)\n",
    "    # Convert to float as otherwise integer division results in all 0 for proba.\n",
    "    proba = count.astype(float) / len(sx)\n",
    "    # Avoid 0 division; remove probabilities == 0.0 (removing them does not change the entropy estimate as 0 * log(1/0) = 0.\n",
    "    proba = proba[proba > 0.0]\n",
    "    return np.sum(proba * np.log(1. / proba)) / log(base)\n",
    "\n",
    "def centropyd(x, y, base=2):\n",
    "    \"\"\" The classic K-L k-nearest neighbor continuous entropy estimator for the\n",
    "        entropy of X conditioned on Y.\n",
    "    \"\"\"\n",
    "    xy = np.c_[x, y]\n",
    "    return entropyd(xy, base) - entropyd(y, base)\n",
    "\n",
    "def midd(x, y, base=2):\n",
    "    \"\"\" Discrete mutual information estimator\n",
    "        Given a list of samples which can be any hashable object\n",
    "    \"\"\"\n",
    "    assert len(x) == len(y), \"Arrays should have same length\"\n",
    "    return entropyd(x, base) - centropyd(x, y, base)\n",
    "\n",
    "\n",
    "def cmidd(x, y, z, base=2):\n",
    "    \"\"\" Discrete mutual information estimator\n",
    "        Given a list of samples which can be any hashable object\n",
    "    \"\"\"\n",
    "    assert len(x) == len(y) == len(z), \"Arrays should have same length\"\n",
    "    xz = np.c_[x, z]\n",
    "    yz = np.c_[y, z]\n",
    "    xyz = np.c_[x, y, z]\n",
    "    return entropyd(xz, base) + entropyd(yz, base) - entropyd(xyz, base) - entropyd(z, base)\n",
    "\n",
    "\n",
    "def entropy(x, k=3, base=2):\n",
    "    \"\"\" The classic K-L k-nearest neighbor continuous entropy estimator\n",
    "        x should be a list of vectors, e.g. x = [[1.3], [3.7], [5.1], [2.4]]\n",
    "        if x is a one-dimensional scalar and we have four samples\n",
    "    \"\"\"\n",
    "    assert k <= len(x) - 1, \"Set k smaller than num. samples - 1\"\n",
    "    x = np.asarray(x)\n",
    "    n_elements, n_features = x.shape\n",
    "    x = add_noise(x)\n",
    "    tree = build_tree(x)\n",
    "    nn = query_neighbors(tree, x, k)\n",
    "    const = digamma(n_elements) - digamma(k) + n_features * log(2)\n",
    "    return (const + n_features * np.log(nn).mean()) / log(base)\n",
    "\n",
    "\n",
    "def centropy(x, y, k=3, base=2):\n",
    "    \"\"\" \n",
    "    The classic K-L k-nearest neighbor continuous entropy estimator for the\n",
    "    entropy of X conditioned on Y.\n",
    "    \"\"\"\n",
    "    xy = np.c_[x, y]\n",
    "    entropy_union_xy = entropy(xy, k=k, base=base)\n",
    "    entropy_y = entropy(y, k=k, base=base)\n",
    "    return entropy_union_xy - entropy_y\n",
    "\n",
    "\n",
    "def tc(xs, k=3, base=2):\n",
    "    xs_columns = np.expand_dims(xs, axis=0).T\n",
    "    entropy_features = [entropy(col, k=k, base=base) for col in xs_columns]\n",
    "    return np.sum(entropy_features) - entropy(xs, k, base)\n",
    "\n",
    "\n",
    "def ctc(xs, y, k=3, base=2):\n",
    "    xs_columns = np.expand_dims(xs, axis=0).T\n",
    "    centropy_features = [centropy(col, y, k=k, base=base)\n",
    "                         for col in xs_columns]\n",
    "    return np.sum(centropy_features) - centropy(xs, y, k, base)\n",
    "\n",
    "\n",
    "def corex(xs, ys, k=3, base=2):\n",
    "    xs_columns = np.expand_dims(xs, axis=0).T\n",
    "    cmi_features = [mi(col, ys, k=k, base=base) for col in xs_columns]\n",
    "    return np.sum(cmi_features) - mi(xs, ys, k=k, base=base)\n",
    "\n",
    "\n",
    "def mi(x, y, z=None, k=3, base=2, alpha=0):\n",
    "    \"\"\" \n",
    "    Mutual information of x and y (conditioned on z if z is not None)\n",
    "    x, y should be a list of vectors, e.g. x = [[1.3], [3.7], [5.1], [2.4]]\n",
    "    if x is a one-dimensional scalar and we have four samples\n",
    "    \"\"\"\n",
    "    assert len(x) == len(y), \"Arrays should have same length\"\n",
    "    assert k <= len(x) - 1, \"Set k smaller than num. samples - 1\"\n",
    "    x, y = np.asarray(x), np.asarray(y)\n",
    "    x, y = x.reshape(x.shape[0], -1), y.reshape(y.shape[0], -1)\n",
    "    x = add_noise(x)\n",
    "    y = add_noise(y)\n",
    "    points = [x, y]\n",
    "    if z is not None:\n",
    "        z = np.asarray(z)\n",
    "        z = z.reshape(z.shape[0], -1)\n",
    "        points.append(z)\n",
    "    points = np.hstack(points)\n",
    "    # Find nearest neighbors in joint space, p=inf means max-norm\n",
    "    tree = build_tree(points)\n",
    "    dvec = query_neighbors(tree, points, k)\n",
    "    if z is None:\n",
    "        a, b, c, d = avgdigamma(x, dvec), avgdigamma(\n",
    "            y, dvec), digamma(k), digamma(len(x))\n",
    "        if alpha > 0:\n",
    "            d += lnc_correction(tree, points, k, alpha)\n",
    "    else:\n",
    "        xz = np.c_[x, z]\n",
    "        yz = np.c_[y, z]\n",
    "        a, b, c, d = avgdigamma(xz, dvec), avgdigamma(\n",
    "            yz, dvec), avgdigamma(z, dvec), digamma(k)\n",
    "    return (-a - b + c + d) / log(base)\n",
    "\n",
    "\n",
    "def cmi(x, y, z, k=3, base=2):\n",
    "    \"\"\" Mutual information of x and y, conditioned on z\n",
    "        Legacy function. Use mi(x, y, z) directly.\n",
    "    \"\"\"\n",
    "    return mi(x, y, z=z, k=k, base=base)\n",
    "\n",
    "\n",
    "\n",
    "def lnc_correction(tree, points, k, alpha):\n",
    "    e = 0\n",
    "    n_sample = points.shape[0]\n",
    "    for point in points:\n",
    "        # Find k-nearest neighbors in joint space, p=inf means max norm\n",
    "        knn = tree.query(point[None, :], k=k+1, return_distance=False)[0]\n",
    "        knn_points = points[knn]\n",
    "        # Substract mean of k-nearest neighbor points\n",
    "        knn_points = knn_points - knn_points[0]\n",
    "        # Calculate covariance matrix of k-nearest neighbor points, obtain eigen vectors\n",
    "        covr = knn_points.T @ knn_points / k\n",
    "        _, v = la.eig(covr)\n",
    "        # Calculate PCA-bounding box using eigen vectors\n",
    "        V_rect = np.log(np.abs(knn_points @ v).max(axis=0)).sum()\n",
    "        # Calculate the volume of original box\n",
    "        log_knn_dist = np.log(np.abs(knn_points).max(axis=0)).sum()\n",
    "\n",
    "        # Perform local non-uniformity checking and update correction term\n",
    "        if V_rect < log_knn_dist + np.log(alpha):\n",
    "            e += (log_knn_dist - V_rect) / n_sample\n",
    "    return e\n",
    "\n",
    "\n",
    "\n",
    "def tcd(xs, base=2):\n",
    "    xs_columns = np.expand_dims(xs, axis=0).T\n",
    "    entropy_features = [entropyd(col, base=base) for col in xs_columns]\n",
    "    return np.sum(entropy_features) - entropyd(xs, base)\n",
    "\n",
    "\n",
    "def ctcd(xs, y, base=2):\n",
    "    xs_columns = np.expand_dims(xs, axis=0).T\n",
    "    centropy_features = [centropyd(col, y, base=base) for col in xs_columns]\n",
    "    return np.sum(centropy_features) - centropyd(xs, y, base)\n",
    "\n",
    "\n",
    "def corexd(xs, ys, base=2):\n",
    "    xs_columns = np.expand_dims(xs, axis=0).T\n",
    "    cmi_features = [midd(col, ys, base=base) for col in xs_columns]\n",
    "    return np.sum(cmi_features) - midd(xs, ys, base)\n",
    "\n",
    "\n",
    "# MIXED ESTIMATORS\n",
    "def micd(x, y, k=3, base=2, warning=True):\n",
    "    \"\"\" If x is continuous and y is discrete, compute mutual information\n",
    "    \"\"\"\n",
    "    assert len(x) == len(y), \"Arrays should have same length\"\n",
    "    entropy_x = entropy(x, k, base)\n",
    "\n",
    "    y_unique, y_count = np.unique(y, return_counts=True, axis=0)\n",
    "    y_proba = y_count / len(y)\n",
    "\n",
    "    entropy_x_given_y = 0.\n",
    "    for yval, py in zip(y_unique, y_proba):\n",
    "        x_given_y = x[(y == yval).all(axis=1)]\n",
    "        if k <= len(x_given_y) - 1:\n",
    "            entropy_x_given_y += py * entropy(x_given_y, k, base)\n",
    "        else:\n",
    "            if warning:\n",
    "                warnings.warn(\"Warning, after conditioning, on y={yval} insufficient data. \"\n",
    "                              \"Assuming maximal entropy in this case.\".format(yval=yval))\n",
    "            entropy_x_given_y += py * entropy_x\n",
    "    return abs(entropy_x - entropy_x_given_y)  # units already applied\n",
    "\n",
    "\n",
    "def midc(x, y, k=3, base=2, warning=True):\n",
    "    return micd(y, x, k, base, warning)\n",
    "\n",
    "\n",
    "def centropycd(x, y, k=3, base=2, warning=True):\n",
    "    return entropy(x, base) - micd(x, y, k, base, warning)\n",
    "\n",
    "\n",
    "def centropydc(x, y, k=3, base=2, warning=True):\n",
    "    return centropycd(y, x, k=k, base=base, warning=warning)\n",
    "\n",
    "\n",
    "def ctcdc(xs, y, k=3, base=2, warning=True):\n",
    "    xs_columns = np.expand_dims(xs, axis=0).T\n",
    "    centropy_features = [centropydc(\n",
    "        col, y, k=k, base=base, warning=warning) for col in xs_columns]\n",
    "    return np.sum(centropy_features) - centropydc(xs, y, k, base, warning)\n",
    "\n",
    "\n",
    "def ctccd(xs, y, k=3, base=2, warning=True):\n",
    "    return ctcdc(y, xs, k=k, base=base, warning=warning)\n",
    "\n",
    "\n",
    "def corexcd(xs, ys, k=3, base=2, warning=True):\n",
    "    return corexdc(ys, xs, k=k, base=base, warning=warning)\n",
    "\n",
    "\n",
    "def corexdc(xs, ys, k=3, base=2, warning=True):\n",
    "    return tcd(xs, base) - ctcdc(xs, ys, k, base, warning)\n",
    "\n",
    "\n",
    "# UTILITY FUNCTIONS\n",
    "\n",
    "def add_noise(x, intens=1e-10):\n",
    "    # small noise to break degeneracy, see doc.\n",
    "    return x + intens * np.random.random_sample(x.shape)\n",
    "\n",
    "\n",
    "def query_neighbors(tree, x, k):\n",
    "    return tree.query(x, k=k + 1)[0][:, k]\n",
    "\n",
    "\n",
    "def count_neighbors(tree, x, r):\n",
    "    return tree.query_radius(x, r, count_only=True)\n",
    "\n",
    "\n",
    "def avgdigamma(points, dvec):\n",
    "    # This part finds number of neighbors in some radius in the marginal space\n",
    "    # returns expectation value of <psi(nx)>\n",
    "    tree = build_tree(points)\n",
    "    dvec = dvec - 1e-15\n",
    "    num_points = count_neighbors(tree, points, dvec)\n",
    "    return np.mean(digamma(num_points))\n",
    "\n",
    "\n",
    "def build_tree(points):\n",
    "    if points.shape[1] >= 20:\n",
    "        return BallTree(points, metric='chebyshev')\n",
    "    return KDTree(points, metric='chebyshev')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f828f3f-79ba-4aa3-b9ec-de31193a9fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstMI(X, y, nTimeSteps, temporaryKeys, base=2):\n",
    "    maxMI = 0\n",
    "    indexMIMax = 0\n",
    "    for k in range(len(temporaryKeys)):\n",
    "        keys = [temporaryKeys[k] + str(s) for s in np.arange(0, nTimeSteps, 1).tolist()]\n",
    "        miValue = np.abs(entropyd(y.values, base) - centropyd(y.values, X[keys].values, base))\n",
    "        if miValue > maxMI:\n",
    "            maxMI = miValue\n",
    "            indexMIMax = k\n",
    "    #Elimino la primera variable seleccionada de X y la añado a z\n",
    "    keys = [temporaryKeys[indexMIMax] + str(s) for s in np.arange(0, nTimeSteps, 1).tolist()]\n",
    "    z = X[keys].values\n",
    "    X = X.drop(columns=keys)\n",
    "    keyToReturn = temporaryKeys[indexMIMax]\n",
    "    temporaryKeys.remove(keyToReturn)\n",
    "    return X, z, keyToReturn, temporaryKeys, maxMI\n",
    "\n",
    "def myCondMI(X, y, z, nTimeSteps, temporaryKeys, base=2):\n",
    "    maxMI = 0\n",
    "    indexMIMax = 0\n",
    "    for k in range(len(temporaryKeys)):\n",
    "        keys = [temporaryKeys[k] + str(s) for s in np.arange(0, nTimeSteps, 1).tolist()]\n",
    "        miValue = np.abs(cmidd(y.values, X[keys].values, z))\n",
    "        if miValue > maxMI:\n",
    "            maxMI = miValue\n",
    "            indexMIMax = k\n",
    "    #Elimino la primera variable seleccionada de X y la añado a z\n",
    "    keys = [temporaryKeys[indexMIMax] + str(s) for s in np.arange(0, nTimeSteps, 1).tolist()]\n",
    "    z = np.append(z, X[keys].values, axis=1)\n",
    "    X = X.drop(columns=keys)\n",
    "    keyToReturn = temporaryKeys[indexMIMax]\n",
    "    temporaryKeys.remove(keyToReturn)\n",
    "    return X, z, keyToReturn, temporaryKeys, maxMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb01619-375d-40bf-b978-58e6a1bbf0d9",
   "metadata": {},
   "source": [
    "# Code - Dynamic CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "444b0e10-47e0-4b9f-b6e3-95308d302349",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "n = 4\n",
    "\n",
    "X_train = np.load(\"../splits_14_days/notbalanced/split_\" + str(i) +\n",
    "                                              \"/X_train_tensor_\" + str(n)+ \".npy\")\n",
    "y_train = pd.read_csv(\"../splits_14_days/notbalanced/split_\" + str(i) +\n",
    "                      \"/y_train_\" + str(n)+ \".csv\",\n",
    "                     index_col=0)\n",
    "\n",
    "X_val = np.load(\"../splits_14_days/notbalanced/split_\" + str(i) +\n",
    "                                              \"/X_val_tensor_\" + str(n)+ \".npy\")\n",
    "y_val = pd.read_csv(\"../splits_14_days/notbalanced/split_\" + str(i) +\n",
    "                    \"/y_val_\" + str(n)+ \".csv\",\n",
    "                   index_col=0)\n",
    "\n",
    "\n",
    "temporaryKeys = ['AMG', 'ATF', 'CAR', 'CF1', 'CF2', 'CF3',\n",
    "       'CF4', 'Falta', 'GCC', 'GLI', 'LIN', 'LIP', 'MAC', 'MON', 'NTI', 'OTR',\n",
    "       'OXA', 'PAP', 'PEN', 'POL', 'QUI', 'SUL', 'TTC', 'pc_acinet',\n",
    "       'pc_enterob', 'pc_enteroc', 'pc_pseud', 'pc_staph', 'pc_stenot',\n",
    "       'pc_no_germ', 'isVM', 'numberOfPatients', 'numberOfPatientsMR',\n",
    "       'neighbor_AMG', 'neighbor_ATF', 'neighbor_CAR', 'neighbor_CF1',\n",
    "       'neighbor_CF2', 'neighbor_CF3', 'neighbor_CF4', 'neighbor_Falta',\n",
    "       'neighbor_GCC', 'neighbor_GLI', 'neighbor_LIN', 'neighbor_LIP',\n",
    "       'neighbor_MAC', 'neighbor_MON', 'neighbor_NTI', 'neighbor_OTR',\n",
    "       'neighbor_OXA', 'neighbor_PAP', 'neighbor_PEN', 'neighbor_POL',\n",
    "       'neighbor_QUI', 'neighbor_SUL', 'neighbor_TTC']\n",
    "\n",
    "data_train = []\n",
    "data_val = []\n",
    "\n",
    "# Transform the .npy into a .csv breaking the temporal dimensions\n",
    "for patient in range(X_train.shape[0]): \n",
    "    row_data = {}  \n",
    "    for feature_idx, feature_name in enumerate(temporaryKeys): \n",
    "        for time_step in range(X_train.shape[1]):  \n",
    "            # Create the column 'feature_name' + time_step: AMG0, AMG1, etc.\n",
    "            column_name = f\"{feature_name}{time_step}\"\n",
    "            row_data[column_name] = X_train[patient, time_step, feature_idx]  \n",
    "    data_train.append(row_data) \n",
    "\n",
    "\n",
    "for patient in range(X_val.shape[0]): \n",
    "    row_data = {}  \n",
    "    for feature_idx, feature_name in enumerate(temporaryKeys): \n",
    "        for time_step in range(X_val.shape[1]):  \n",
    "            # Create the column 'feature_name' + time_step\n",
    "            column_name = f\"{feature_name}{time_step}\"\n",
    "            row_data[column_name] = X_val[patient, time_step, feature_idx]  \n",
    "    data_val.append(row_data)  \n",
    "\n",
    "df_train = pd.DataFrame(data_train)\n",
    "df_val = pd.DataFrame(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e45fe3e6-7c79-4eef-b95e-0cd2b9d760a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([df_train, df_val], axis=0)\n",
    "y = pd.concat([y_train, y_val], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18f23e1d-5769-4286-a968-458999c4d3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primera feature seleccionada: neighbor_QUI\n",
      "(2526, 770)\n",
      "Siguiente feature seleccionada: neighbor_CAR\n",
      "(2526, 756)\n",
      "54\n",
      "Siguiente feature seleccionada: neighbor_PAP\n",
      "(2526, 742)\n",
      "53\n",
      "Siguiente feature seleccionada: neighbor_OXA\n",
      "(2526, 728)\n",
      "52\n",
      "Siguiente feature seleccionada: numberOfPatients\n",
      "(2526, 714)\n",
      "51\n",
      "Siguiente feature seleccionada: neighbor_CF3\n",
      "(2526, 700)\n",
      "50\n",
      "Siguiente feature seleccionada: neighbor_PEN\n",
      "(2526, 686)\n",
      "49\n",
      "Siguiente feature seleccionada: neighbor_GLI\n",
      "(2526, 672)\n",
      "48\n",
      "Siguiente feature seleccionada: CAR\n",
      "(2526, 658)\n",
      "47\n",
      "Siguiente feature seleccionada: ATF\n",
      "(2526, 644)\n",
      "46\n",
      "Siguiente feature seleccionada: PAP\n",
      "(2526, 630)\n",
      "45\n",
      "Siguiente feature seleccionada: neighbor_NTI\n",
      "(2526, 616)\n",
      "44\n",
      "Siguiente feature seleccionada: AMG\n",
      "(2526, 602)\n",
      "43\n",
      "Siguiente feature seleccionada: CF1\n",
      "(2526, 588)\n",
      "42\n",
      "Siguiente feature seleccionada: CF2\n",
      "(2526, 574)\n",
      "41\n",
      "Siguiente feature seleccionada: CF3\n",
      "(2526, 560)\n",
      "40\n",
      "Siguiente feature seleccionada: CF4\n",
      "(2526, 546)\n",
      "39\n",
      "Siguiente feature seleccionada: Falta\n",
      "(2526, 532)\n",
      "38\n",
      "Siguiente feature seleccionada: GLI\n",
      "(2526, 518)\n",
      "37\n",
      "Siguiente feature seleccionada: LIN\n",
      "(2526, 504)\n",
      "36\n",
      "Siguiente feature seleccionada: MAC\n",
      "(2526, 490)\n",
      "35\n",
      "Siguiente feature seleccionada: SUL\n",
      "(2526, 476)\n",
      "34\n",
      "Siguiente feature seleccionada: pc_enteroc\n",
      "(2526, 462)\n",
      "33\n",
      "Siguiente feature seleccionada: pc_pseud\n",
      "(2526, 448)\n",
      "32\n",
      "Siguiente feature seleccionada: pc_staph\n",
      "(2526, 434)\n",
      "31\n",
      "Siguiente feature seleccionada: neighbor_CF2\n",
      "(2526, 420)\n",
      "30\n",
      "Siguiente feature seleccionada: neighbor_GCC\n",
      "(2526, 406)\n",
      "29\n",
      "Siguiente feature seleccionada: neighbor_OTR\n",
      "(2526, 392)\n",
      "28\n",
      "Siguiente feature seleccionada: neighbor_POL\n",
      "(2526, 378)\n",
      "27\n",
      "Siguiente feature seleccionada: neighbor_TTC\n",
      "(2526, 364)\n",
      "26\n",
      "Siguiente feature seleccionada: GCC\n",
      "(2526, 350)\n",
      "25\n",
      "Siguiente feature seleccionada: LIP\n",
      "(2526, 336)\n",
      "24\n",
      "Siguiente feature seleccionada: MON\n",
      "(2526, 322)\n",
      "23\n",
      "Siguiente feature seleccionada: NTI\n",
      "(2526, 308)\n",
      "22\n",
      "Siguiente feature seleccionada: neighbor_CF1\n",
      "(2526, 294)\n",
      "21\n",
      "Siguiente feature seleccionada: OTR\n",
      "(2526, 280)\n",
      "20\n",
      "Siguiente feature seleccionada: OXA\n",
      "(2526, 266)\n",
      "19\n",
      "Siguiente feature seleccionada: POL\n",
      "(2526, 252)\n",
      "18\n",
      "Siguiente feature seleccionada: TTC\n",
      "(2526, 238)\n",
      "17\n",
      "Siguiente feature seleccionada: pc_acinet\n",
      "(2526, 224)\n",
      "16\n",
      "Siguiente feature seleccionada: pc_enterob\n",
      "(2526, 210)\n",
      "15\n",
      "Siguiente feature seleccionada: pc_stenot\n",
      "(2526, 196)\n",
      "14\n",
      "Siguiente feature seleccionada: numberOfPatientsMR\n",
      "(2526, 182)\n",
      "13\n",
      "Siguiente feature seleccionada: neighbor_LIN\n",
      "(2526, 168)\n",
      "12\n",
      "Siguiente feature seleccionada: neighbor_MON\n",
      "(2526, 154)\n",
      "11\n",
      "Siguiente feature seleccionada: PEN\n",
      "(2526, 140)\n",
      "10\n",
      "Siguiente feature seleccionada: QUI\n",
      "(2526, 126)\n",
      "9\n",
      "Siguiente feature seleccionada: pc_no_germ\n",
      "(2526, 112)\n",
      "8\n",
      "Siguiente feature seleccionada: isVM\n",
      "(2526, 98)\n",
      "7\n",
      "Siguiente feature seleccionada: neighbor_AMG\n",
      "(2526, 84)\n",
      "6\n",
      "Siguiente feature seleccionada: neighbor_ATF\n",
      "(2526, 70)\n",
      "5\n",
      "Siguiente feature seleccionada: neighbor_CF4\n",
      "(2526, 56)\n",
      "4\n",
      "Siguiente feature seleccionada: neighbor_Falta\n",
      "(2526, 42)\n",
      "3\n",
      "Siguiente feature seleccionada: neighbor_LIP\n",
      "(2526, 28)\n",
      "2\n",
      "Siguiente feature seleccionada: neighbor_MAC\n",
      "(2526, 14)\n",
      "1\n",
      "Siguiente feature seleccionada: neighbor_SUL\n",
      "(2526, 0)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "NTimeSteps = 14\n",
    "NFeatures = 56\n",
    "\n",
    "temporaryKeys = ['AMG', 'ATF', 'CAR', 'CF1', 'CF2', 'CF3',\n",
    "       'CF4', 'Falta', 'GCC', 'GLI', 'LIN', 'LIP', 'MAC', 'MON', 'NTI', 'OTR',\n",
    "       'OXA', 'PAP', 'PEN', 'POL', 'QUI', 'SUL', 'TTC', 'pc_acinet',\n",
    "       'pc_enterob', 'pc_enteroc', 'pc_pseud', 'pc_staph', 'pc_stenot',\n",
    "       'pc_no_germ', 'isVM', 'numberOfPatients', 'numberOfPatientsMR',\n",
    "       'neighbor_AMG', 'neighbor_ATF', 'neighbor_CAR', 'neighbor_CF1',\n",
    "       'neighbor_CF2', 'neighbor_CF3', 'neighbor_CF4', 'neighbor_Falta',\n",
    "       'neighbor_GCC', 'neighbor_GLI', 'neighbor_LIN', 'neighbor_LIP',\n",
    "       'neighbor_MAC', 'neighbor_MON', 'neighbor_NTI', 'neighbor_OTR',\n",
    "       'neighbor_OXA', 'neighbor_PAP', 'neighbor_PEN', 'neighbor_POL',\n",
    "       'neighbor_QUI', 'neighbor_SUL', 'neighbor_TTC']\n",
    "\n",
    "\n",
    "NSubFeatures = np.zeros(X.shape[1])\n",
    "\n",
    "indexesSelected = []\n",
    "MIvalues = []\n",
    "for j in range(NFeatures):\n",
    "    if j == 0:\n",
    "        X, z, featureSelected, temporaryKeys, maxMI = firstMI(X, y, NTimeSteps, temporaryKeys)\n",
    "        indexesSelected.append(featureSelected)\n",
    "        MIvalues.append(maxMI)\n",
    "        print(\"Primera feature seleccionada:\", featureSelected)\n",
    "        print(X.shape)\n",
    "    else:\n",
    "        X, z, featureSelected, temporaryKeys, maxMI = myCondMI(X, y, z, NTimeSteps, temporaryKeys)\n",
    "        indexesSelected.append(featureSelected)\n",
    "        MIvalues.append(maxMI)\n",
    "        print(\"Siguiente feature seleccionada:\", featureSelected)\n",
    "        print(X.shape)\n",
    "        print(len(temporaryKeys))\n",
    "results = pd.DataFrame(data=np.array([np.array(indexesSelected), np.array(MIvalues)]).T, columns=[\"Keys\", \"MIValues\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bef5e5a9-68d9-4a85-b6de-5e85bed6a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"results_MI_COND_dynamic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef91777-4ec8-4392-99ed-36ff2c699a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
