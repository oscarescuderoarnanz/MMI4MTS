{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a0f29a-1eee-4388-83af-790b385f9a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../Libraries/\")\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6542a7-1c54-4bc6-ade1-55fcedd50ad9",
   "metadata": {},
   "source": [
    "# Functions for the dynamic and static models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4d1065-e7ea-412f-80ca-922568d50ce2",
   "metadata": {},
   "source": [
    "#### Dynamic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c320e-e232-410c-af27-6d539f163b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dynamic_model(n_timesteps, mask_value, n_dynamic_features, \n",
    "                hidden_layer_size, dropout_rate, lr_scheduler):\n",
    "    # Dynamic preprocessing.\n",
    "    dynamic_input = tf.keras.layers.Input(shape=(n_timesteps, n_dynamic_features,))\n",
    "    masked = tf.keras.layers.Masking(mask_value=mask_value)(dynamic_input)\n",
    "    gru_encoder = tf.keras.layers.GRU(\n",
    "        hidden_layer_size,\n",
    "        dropout=dropout_rate,\n",
    "        return_sequences=False,\n",
    "        activation='tanh',\n",
    "        use_bias=False\n",
    "    )(masked)\n",
    "    \n",
    "    # Concatenation\n",
    "    output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(gru_encoder)\n",
    "    \n",
    "    model = tf.keras.Model([dynamic_input], [output])\n",
    "    customized_loss = utils.weighted_binary_crossentropy(hyperparameters)\n",
    "    myOptimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n",
    "    model.compile(loss=customized_loss, optimizer=myOptimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d61408-716e-45d0-8e47-8bc9b173062e",
   "metadata": {},
   "source": [
    "#### Static model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d8072e-b8c0-4be3-848b-cd4c58d8cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_static_model(n_timesteps, mask_value, n_static_features, \n",
    "                hidden_layer_size, dropout_rate, lr_scheduler):\n",
    "    # Static preprocessing.\n",
    "    static_input = tf.keras.layers.Input(shape=(n_static_features))\n",
    "    hidden_layer = tf.keras.layers.Dense(\n",
    "        hidden_layer_size,\n",
    "        activation='tanh'\n",
    "    )(static_input)\n",
    "    \n",
    "    # Concatenation\n",
    "    output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
    "    \n",
    "    model = tf.keras.Model([static_input], [output])\n",
    "    customized_loss = utils.weighted_binary_crossentropy(hyperparameters)\n",
    "    myOptimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n",
    "    model.compile(loss=customized_loss, optimizer=myOptimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454c858-62e1-46be-9d67-53d3578c321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network(X_train, X_train_static, y_train, X_val, X_val_static, y_val, hyperparameters, seed, model_type='dynamic'):\n",
    "    model = None\n",
    "    if model_type == 'dynamic':\n",
    "        model = build_dynamic_model(\n",
    "            hyperparameters[\"n_timesteps\"], hyperparameters[\"maskValue\"], hyperparameters[\"n_dynamic_features\"], \n",
    "            hyperparameters[\"layers\"], hyperparameters[\"dropout_rate\"], hyperparameters[\"lr_scheduler\"]\n",
    "        )\n",
    "    elif model_type == 'static':\n",
    "        model = build_static_model(\n",
    "            hyperparameters[\"n_timesteps\"], hyperparameters[\"maskValue\"], hyperparameters[\"n_static_features\"], \n",
    "            hyperparameters[\"layers\"], hyperparameters[\"dropout_rate\"], hyperparameters[\"lr_scheduler\"]\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_type: {model_type}. Please use 'static' or 'dynamic'.\")\n",
    "    \n",
    "    try:\n",
    "        earlystopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=hyperparameters[\"monitor\"],\n",
    "            min_delta=hyperparameters[\"mindelta\"],\n",
    "            patience=hyperparameters[\"patience\"], \n",
    "            restore_best_weights=True,\n",
    "            mode=\"min\"\n",
    "        )\n",
    "\n",
    "        # Fit the model based on the selected model_type\n",
    "        if model_type == 'dynamic':\n",
    "            hist = model.fit(\n",
    "                x=X_train, y=y_train,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=[earlystopping], batch_size=hyperparameters['batch_size'], epochs=hyperparameters['epochs'],\n",
    "                verbose=hyperparameters['verbose'])\n",
    "            \n",
    "        elif model_type == 'static':\n",
    "            hist = model.fit( x=[X_train_static.values], y=y_train,\n",
    "                             validation_data=([X_val_static.values], y_val),\n",
    "                             callbacks=[earlystopping], batch_size=hyperparameters['batch_size'], epochs=hyperparameters['epochs'], verbose=0\n",
    "                            )\n",
    "\n",
    "        return model, hist, earlystopping\n",
    "    except KeyboardInterrupt:\n",
    "        print('Training duration (s):', time.time() - global_start_time)\n",
    "        return model, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d3970-dadf-4d87-ba61-22289d99bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myCVGrid(hyperparameters, dropout, lr_scheduler, layers, split, seed, model_type):\n",
    "    bestHyperparameters = {}\n",
    "    bestMetricDev = np.inf\n",
    "\n",
    "    for k in range(len(dropout)):\n",
    "        for l in range(len(layers)):\n",
    "            for m in range(len(lr_scheduler)):\n",
    "                v_early = []\n",
    "                v_metric_dev = []\n",
    "                v_hist = []\n",
    "                v_val_loss = []\n",
    "\n",
    "                hyperparameters_copy = hyperparameters.copy()\n",
    "                hyperparameters_copy['dropout_rate'] = dropout[k]\n",
    "                hyperparameters_copy['layers'] = layers[l]\n",
    "                hyperparameters_copy['lr_scheduler'] = lr_scheduler[m]\n",
    "                \n",
    "                for n in range(5):\n",
    "\n",
    "                    X_train = np.load(\"../../ORIGINAL_DATA/splits_14_days/notbalanced/split_\" + str(i) +\n",
    "                                          \"/X_train_tensor_\" + str(n)+ \".npy\")\n",
    "                    X_train_static = pd.read_csv(\"../../ORIGINAL_DATA/splits_14_days/notbalanced/split_\" + str(i) +\n",
    "                                             \"/X_train_static_\" + str(n)+ \".csv\", index_col=0)\n",
    "                    y_train = pd.read_csv(\"../../ORIGINAL_DATA/splits_14_days/notbalanced/split_\" + str(i) +\n",
    "                                          \"/y_train_\" + str(n)+ \".csv\",\n",
    "                                         index_col=0)\n",
    "                    X_val = np.load(\"../../ORIGINAL_DATA/splits_14_days/notbalanced/split_\" + str(i) +\n",
    "                                        \"/X_val_tensor_\" + str(n)+ \".npy\")\n",
    "                    X_val_static = pd.read_csv(\"../../ORIGINAL_DATA/splits_14_days/notbalanced/split_\" + str(i) +\n",
    "                                             \"/X_val_static_\" + str(n)+ \".csv\", index_col=0)\n",
    "                    y_val = pd.read_csv(\"../../ORIGINAL_DATA/splits_14_days/notbalanced/split_\" + str(i) +\n",
    "                                        \"/y_val_\" + str(n)+ \".csv\",\n",
    "                                       index_col=0)\n",
    "\n",
    "                    utils.reset_keras()\n",
    "                    model, hist, early = run_network(\n",
    "                        X_train, X_train_static, \n",
    "                        y_train,\n",
    "                        X_val, X_val_static, \n",
    "                        y_val,\n",
    "                        hyperparameters_copy,  \n",
    "                        seed,\n",
    "                        model_type\n",
    "                    )\n",
    "                                        \n",
    "                    v_early.append(early)\n",
    "                    v_hist.append(hist)\n",
    "                    v_val_loss.append(np.min(hist.history[\"val_loss\"]))\n",
    "                    \n",
    "                metric_dev = np.mean(v_val_loss)\n",
    "                if metric_dev < bestMetricDev:\n",
    "                    bestMetricDev = metric_dev\n",
    "                    bestHyperparameters = {\n",
    "                        'dropout_rate': dropout[k],\n",
    "                        'layers': layers[l],\n",
    "                        'lr_scheduler': lr_scheduler[m]\n",
    "                    }\n",
    "\n",
    "    return bestHyperparameters, X_train, y_train, X_train_static, X_val, y_val, X_val_static"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b305f799-389d-4a1e-a2b8-a7d31b87c31d",
   "metadata": {},
   "source": [
    "# Functions for the LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e815ab-c1f3-4ae9-86e4-2b5d36ff1001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_LR(hyperparameters):\n",
    "    # Static preprocessing.\n",
    "    static_input = tf.keras.layers.Input(shape=(2))\n",
    "    # Output\n",
    "    output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(static_input)\n",
    "    \n",
    "    model = tf.keras.Model([static_input], [output])\n",
    "    customized_loss = utils.weighted_binary_crossentropy(hyperparameters)\n",
    "    myOptimizer = tf.keras.optimizers.Adam(learning_rate=hyperparameters[\"lr_scheduler\"])\n",
    "    model.compile(loss=customized_loss, optimizer=myOptimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee3aac-35f6-4c22-a380-e07e15474c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network_LR(X_train, y_train, X_val, y_val, hyperparameters, seed):\n",
    "    model = None\n",
    "    model = build_LR(hyperparameters)\n",
    "    try:\n",
    "        earlystopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=hyperparameters[\"monitor\"],\n",
    "            min_delta=hyperparameters[\"mindelta\"],\n",
    "            patience=hyperparameters[\"patience\"],  # 30\n",
    "            restore_best_weights=True,\n",
    "            mode=\"min\"\n",
    "        )\n",
    "    \n",
    "        hist = model.fit(\n",
    "            x=X_train, y=y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[earlystopping], batch_size=hyperparameters['batch_size'], epochs=hyperparameters['epochs'],\n",
    "            verbose=hyperparameters['verbose']\n",
    "        )\n",
    "                                \n",
    "        return model, hist, earlystopping\n",
    "    except KeyboardInterrupt:\n",
    "        print('Training duration (s):', time.time() - global_start_time)\n",
    "        return model, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c5cbe-df71-4562-b035-8047ee7db2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def myCVGrid_LR(X_prev_train, y_prev_train, hyperparameters, lr_scheduler, seed):\n",
    "    bestHyperparameters = {}\n",
    "    bestMetricDev = np.inf\n",
    "\n",
    "    for j in range(len(lr_scheduler)):\n",
    "        v_early = []\n",
    "        v_metric_dev = []\n",
    "        v_hist = []\n",
    "        v_val_loss = []\n",
    "        kf = KFold(n_splits=2)\n",
    "\n",
    "        hyperparameters_copy = hyperparameters.copy()\n",
    "        hyperparameters_copy['lr_scheduler'] = lr_scheduler[j]\n",
    "        \n",
    "        for train, val in kf.split(X_prev_train):\n",
    "            #Load train and validation\n",
    "            X_train = X_prev_train.iloc[train]\n",
    "            y_train = y_prev_train.iloc[train]\n",
    "            \n",
    "            X_val = X_prev_train.iloc[val]\n",
    "            y_val = y_prev_train.iloc[val]\n",
    "            \n",
    "            # Train the model \n",
    "            model, hist, earlystopping = run_network_LR(X_train, \n",
    "                                                        y_train, \n",
    "                                                        X_val, \n",
    "                                                        y_val, \n",
    "                                                        hyperparameters_copy, \n",
    "                                                        seed)\n",
    "            \n",
    "            \n",
    "            v_early.append(earlystopping)\n",
    "            v_hist.append(hist)\n",
    "            v_val_loss.append(np.min(hist.history[\"val_loss\"]))\n",
    "            \n",
    "            metric_dev = np.mean(v_val_loss)\n",
    "            if metric_dev < bestMetricDev:\n",
    "                bestMetricDev = metric_dev\n",
    "                bestHyperparameters = {\n",
    "                    'lr_scheduler': lr_scheduler[j]\n",
    "                }\n",
    "\n",
    "    return bestHyperparameters, X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32f6694-ff74-4f7b-abd5-17d3046b6cd7",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f0504-75fc-46b2-a43b-30509af9c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(split_directory, best_hyperparameters, y_test_pred, y_train_pred=None, model=None):\n",
    "\n",
    "    if not os.path.exists(split_directory):\n",
    "        os.makedirs(split_directory)\n",
    "\n",
    "    with open(os.path.join(split_directory, \"bestHyperparameters.pkl\"), 'wb') as f:\n",
    "        pickle.dump(best_hyperparameters, f)\n",
    "\n",
    "    with open(os.path.join(split_directory, \"y_test_pred.pkl\"), 'wb') as f:\n",
    "        pickle.dump(y_test_pred, f)\n",
    "        \n",
    "    if y_train_pred is not None:\n",
    "        with open(os.path.join(split_directory, \"y_train_pred.pkl\"), 'wb') as f:\n",
    "            pickle.dump(y_train_pred, f)\n",
    "\n",
    "    if model is not None:\n",
    "        model_filename = os.path.join(split_directory, \"model.h5\")\n",
    "        model.save(model_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d43e25-a113-446f-ad8d-aaa3d915106f",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683684a-8fd3-4807-8bb2-317e16228b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [20, 30, 45, 70]\n",
    "\n",
    "tensor = True\n",
    "debug = True\n",
    "balance = True\n",
    "\n",
    "n_max_num = 5\n",
    "n_categorical_features = 3\n",
    "n_numerical_features = 5\n",
    "n_static_features = n_categorical_features + n_numerical_features\n",
    "n_dynamic_features = 56\n",
    "n_timesteps = 14\n",
    "\n",
    "# Hyperparamas of network\n",
    "epochs = 10000\n",
    "batch_size = 128\n",
    "\n",
    "layers = [3, 5, 8, 10, 15, 20, 25, 30, 35, 40, 50]\n",
    "lr_scheduler = [0.0001, 0.001, 0.01, 0.1]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3]\n",
    "\n",
    "w2 = 0.18\n",
    "w1 = 0.82\n",
    "\n",
    "hyperparameters = {\n",
    "    \"n_categorical_features\": n_categorical_features,\n",
    "    \"n_numerical_features\": n_numerical_features,\n",
    "    \"n_static_features\": n_static_features,\n",
    "    \"n_dynamic_features\": n_dynamic_features,\n",
    "    \"n_timesteps\": n_timesteps,\n",
    "    \"w1\":w1, \"w2\":w2, \n",
    "    \"epochs\":epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'maskValue':666,\n",
    "    'monitor': 'val_loss', \n",
    "    \"mindelta\": 0,\n",
    "    \"patience\":30,\n",
    "    'balance': balance,\n",
    "    'optimizer':'adam',\n",
    "    'kfold':5,\n",
    "    'level':3, \n",
    "    'verbose':0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6520fdab-5d0a-4dec-862a-2bfdffd7ddb7",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f0359a-2c73-4181-a7fb-7d89abb3895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model = True\n",
    "\n",
    "if run_model:\n",
    "    v_early = []\n",
    "    loss_dev_stat = []\n",
    "    loss_dev_dyn = []\n",
    "    loss_dev_LR = []\n",
    "    v_models_stat = []\n",
    "    v_models_dyn = []\n",
    "    v_models_LR = []\n",
    "    bestHyperparameters_bySplit_dyn = {}\n",
    "    bestHyperparameters_bySplit_stat = {}\n",
    "    bestHyperparameters_bySplit_LR = {}\n",
    "    y_pred_by_split_stat = {}\n",
    "    y_pred_by_split_dyn = {}\n",
    "    y_pred_by_split_LR = {}\n",
    "\n",
    "\n",
    "    for i in range(4):\n",
    "        X_test_dynamic = np.load(\"../../ORIGINAL_DATA/splits_14_days/notbalanced/split_\" + str(i) + \"/X_test_tensor.npy\")\n",
    "        X_test_static = pd.read_csv(\"../../ORIGINAL_DATA/splits_14_days/notbalanced/split_\" + str(i) + \"/X_test_static.csv\",\n",
    "                                   index_col=0)\n",
    "        y_test = pd.read_csv(\"../../ORIGINAL_DATA/splits_14_days/notbalanced/split_\" + str(i) + \"/y_test.csv\",\n",
    "                            index_col=0)\n",
    "\n",
    "        # DYNAMIC #########################################################################################################\n",
    "        bestHyperparameters_dyn, X_train, y_train, X_train_static, X_val, y_val, X_val_static = myCVGrid(hyperparameters,\n",
    "                                                                                                     dropout_rate,\n",
    "                                                                                                     lr_scheduler,\n",
    "                                                                                                     layers,\n",
    "                                                                                                     i,                                                              \n",
    "                                                                                                     seeds[i],\n",
    "                                                                                                     model_type=\"dynamic\"\n",
    "                                                                                                     )\n",
    "        bestHyperparameters_bySplit_stat[str(i)] = bestHyperparameters_dyn\n",
    "\n",
    "        hyperparameters.update({\n",
    "            \"dropout_rate\": bestHyperparameters_dyn[\"dropout_rate\"],\n",
    "            \"layers\": bestHyperparameters_dyn[\"layers\"],\n",
    "            \"lr_scheduler\": bestHyperparameters_dyn[\"lr_scheduler\"],\n",
    "        })\n",
    "\n",
    "        utils.reset_keras()\n",
    "        model_dyn, hist, early = run_network(\n",
    "            X_train, X_train_static, y_train.individualMRGerm.values,\n",
    "            X_val, X_val_static, y_val.individualMRGerm.values,\n",
    "            hyperparameters, seeds[i], model_type=\"dynamic\"\n",
    "        )\n",
    "\n",
    "        #Save the hyperparameters and predictions\n",
    "        split_directory = f'./Results_LFLR/Dynamic/split_{i}'\n",
    "        y_pred_dynamic = model_dyn.predict(X_test_dynamic)\n",
    "        y_train_pred_dynamic = model_dyn.predict(X_train)\n",
    "        \n",
    "        save_results(split_directory, bestHyperparameters_dyn, y_pred_dynamic, y_train_pred_dynamic, model_dyn)\n",
    "\n",
    "        v_models_dyn.append(model_dyn)\n",
    "        loss_dev_dyn.append(hist.history['val_loss'])\n",
    "        y_pred_by_split_dyn[str(i)] = y_pred_dynamic\n",
    "\n",
    "        # STATIC #########################################################################################################\n",
    "        bestHyperparameters_stat, X_train, y_train, X_train_static, X_val, y_val, X_val_static = myCVGrid(hyperparameters,\n",
    "                                                                                                     dropout_rate,\n",
    "                                                                                                     lr_scheduler,\n",
    "                                                                                                     layers,\n",
    "                                                                                                     i,                                                              \n",
    "                                                                                                     seeds[i],\n",
    "                                                                                                     model_type=\"static\"\n",
    "                                                                                                     )\n",
    "        bestHyperparameters_bySplit_dyn[str(i)] = bestHyperparameters_stat\n",
    "\n",
    "        hyperparameters.update({\n",
    "            \"dropout_rate\": bestHyperparameters_stat[\"dropout_rate\"],\n",
    "            \"layers\": bestHyperparameters_stat[\"layers\"],\n",
    "            \"lr_scheduler\": bestHyperparameters_stat[\"lr_scheduler\"],\n",
    "        })\n",
    "\n",
    "        utils.reset_keras()\n",
    "        model_stat, hist, early = run_network(\n",
    "            X_train, X_train_static, y_train.individualMRGerm.values,\n",
    "            X_val, X_val_static, y_val.individualMRGerm.values,\n",
    "            hyperparameters, seeds[i], model_type=\"static\"\n",
    "        )\n",
    "\n",
    "        #Save the hyperparameters and predictions\n",
    "        split_directory = f'./Results_LFLR/Static/split_{i}'\n",
    "        y_pred_static = model_stat.predict(X_test_static)\n",
    "        y_train_pred_static = model_stat.predict(X_train_static.values)\n",
    "        \n",
    "        save_results(split_directory, bestHyperparameters_stat, y_pred_static, y_train_pred_static, model_stat)\n",
    "\n",
    "        v_models_stat.append(model_stat)\n",
    "        loss_dev_stat.append(hist.history['val_loss'])\n",
    "        y_pred_by_split_stat[str(i)] = y_pred_static\n",
    "\n",
    "        # LR #########################################################################################################\n",
    "        y_train_summary = y_train.reset_index()\n",
    "        y_train_summary[\"y_pred_static\"] = y_train_pred_static\n",
    "        y_train_summary[\"y_pred_dynamic\"] = y_train_pred_dynamic    \n",
    "        y_test_summary = y_test.reset_index()\n",
    "        y_test_summary[\"y_pred_static\"] = y_pred_static\n",
    "        y_test_summary[\"y_pred_dynamic\"] = y_pred_dynamic\n",
    "\n",
    "        bestHyperparameters_LR, X_train_summary, y_train_summary_2, X_val_summary, y_val_summary_2, = myCVGrid_LR(y_train_summary[[\"y_pred_static\", \"y_pred_dynamic\"]], \n",
    "                                                                                                                  y_train_summary[[\"individualMRGerm\"]],\n",
    "                                                                                                                  hyperparameters,\n",
    "                                                                                                                  lr_scheduler,\n",
    "                                                                                                                  seeds[i],\n",
    "                                                                                                                 )\n",
    "\n",
    "        bestHyperparameters_bySplit_LR[str(i)] = bestHyperparameters_LR\n",
    "\n",
    "        hyperparameters.update({\n",
    "            \"lr_scheduler\": bestHyperparameters_LR[\"lr_scheduler\"],\n",
    "        })\n",
    "\n",
    "        utils.reset_keras()\n",
    "        model_LR, hist, earlystopping = run_network_LR(X_train_summary, \n",
    "                                                    y_train_summary_2, \n",
    "                                                    X_val_summary, \n",
    "                                                    y_val_summary_2, \n",
    "                                                    hyperparameters, \n",
    "                                                    seeds[i])\n",
    "        \n",
    "        y_pred = model_LR.predict(y_test_summary[[\"y_pred_static\", \"y_pred_dynamic\"]])\n",
    "\n",
    "        split_directory = f'./Results_LFLR/LR/split_{i}'\n",
    "        save_results(split_directory, bestHyperparameters_LR, y_pred, None, model_LR)\n",
    "\n",
    "        v_models_stat.append(model_LR)\n",
    "        loss_dev_LR.append(hist.history['val_loss'])\n",
    "        y_pred_by_split_LR[str(i)] = y_pred\n",
    "\n",
    "        # Calculate metrics\n",
    "        metrics_dict = utils.calculate_and_save_metrics(\n",
    "        y_test.individualMRGerm.values, \n",
    "        y_pred, \n",
    "        split_directory, \n",
    "        split_index=i\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c42481e-7c81-44ff-ad52-3f26db54ce5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
