{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d118f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# My libraries\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0896ac",
   "metadata": {},
   "source": [
    "## General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688bde93",
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfTimeStep = 14\n",
    "folders = [\"s1\", \"s2\", \"s3\", \"s4\"]\n",
    "\n",
    "norm = \"robustNorm\"\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "print(\"Seleccionando la segunda GPU:\", torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea1b2f",
   "metadata": {},
   "source": [
    "## Train phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f581cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always the same values, do not touch. \n",
    "in_dim_GCN = 1\n",
    "out_dim_GCN = 1\n",
    "\n",
    "# number of max epochs \n",
    "n_epochs = 1000\n",
    "\n",
    "# Early stopping configuration\n",
    "early_stopping_patience = 20\n",
    "\n",
    "# Hyperparameters to be optimized (change this values)\n",
    "h_dropout = [0.15,0.3, 0.45]\n",
    "h_learning_rate = [1e-4, 1e-3, 1e-2, 5e-2]\n",
    "h_decay = [0, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "h_hid_lay = [4, 8, 16, 32]\n",
    "h_layers = [1, 2, 3]\n",
    "seed = [42, 76, 124, 163, 192, 205, 221, 245, 293]\n",
    "\n",
    "fc_layer = [[56, out_dim_GCN]]\n",
    "\n",
    "# Parameters to define type of GCNN and type of output.\n",
    "typeGCN = \"standard_gcnn\"\n",
    "K = [0]\n",
    "\n",
    "params = {# Hyperparameters\n",
    "         'h_layers':h_layers, 'n_epochs':n_epochs, \n",
    "          'h_dropout': h_dropout, 'h_learning_rate': h_learning_rate, \n",
    "          'h_decay':h_decay, 'h_hid_lay': h_hid_lay, 'K':K,\n",
    "          'fc_layer': fc_layer,\n",
    "          # seed to set initialization hyperparameters\n",
    "          'seed': seed, \n",
    "          # Type of output GCN\n",
    "          'typeGCN': typeGCN,\n",
    "          # Dimensions of GCN (input/output)\n",
    "          'in_dim_GCN': in_dim_GCN, 'out_dim_GCN': out_dim_GCN,\n",
    "          # Patiente\n",
    "          'early_stopping_patience':early_stopping_patience}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "way_to_build_graph = \"dtw\"\n",
    "numberOfFeatures = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae68d7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 74\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 176\n",
      "Early stopping at epoch 37\n",
      "Early stopping at epoch 89\n",
      "Early stopping at epoch 59\n",
      "Early stopping at epoch 62\n",
      "Early stopping at epoch 158\n",
      "Early stopping at epoch 35\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 124\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 42\n",
      "Early stopping at epoch 65\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 28\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 71\n",
      "Early stopping at epoch 55\n",
      "Early stopping at epoch 80\n",
      "Early stopping at epoch 35\n",
      "Early stopping at epoch 39\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 30\n",
      "Early stopping at epoch 37\n",
      "Early stopping at epoch 37\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 70\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 40\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 42\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 28\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 65\n",
      "Early stopping at epoch 49\n",
      "Early stopping at epoch 42\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 71\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 64\n",
      "Early stopping at epoch 35\n",
      "Early stopping at epoch 75\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 78\n",
      "Early stopping at epoch 37\n",
      "Early stopping at epoch 98\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 70\n",
      "Early stopping at epoch 58\n",
      "Early stopping at epoch 52\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 223\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 30\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 65\n",
      "Early stopping at epoch 46\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 63\n",
      "Early stopping at epoch 46\n",
      "Early stopping at epoch 71\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 57\n",
      "Early stopping at epoch 35\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 59\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 156\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 37\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 70\n",
      "Early stopping at epoch 90\n",
      "Early stopping at epoch 103\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 161\n",
      "Early stopping at epoch 34\n",
      "Early stopping at epoch 65\n",
      "Early stopping at epoch 42\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 147\n",
      "Early stopping at epoch 54\n",
      "Early stopping at epoch 71\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 51\n",
      "Early stopping at epoch 35\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 49\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 43\n",
      "Early stopping at epoch 37\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 70\n",
      "Early stopping at epoch 120\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 35\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 64\n",
      "Early stopping at epoch 42\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 34\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 34\n",
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 44\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 30\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 34\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 32\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 43\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 30\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 34\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 32\n",
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 37\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 60\n",
      "Early stopping at epoch 40\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 36\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 47\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 42\n",
      "Early stopping at epoch 37\n",
      "Early stopping at epoch 34\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 30\n",
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 42\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 597\n",
      "Early stopping at epoch 518\n",
      "Early stopping at epoch 731\n",
      "Early stopping at epoch 442\n",
      "Early stopping at epoch 577\n",
      "Early stopping at epoch 297\n",
      "Early stopping at epoch 509\n",
      "Early stopping at epoch 622\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 409\n",
      "Early stopping at epoch 52\n",
      "Early stopping at epoch 462\n",
      "Early stopping at epoch 436\n",
      "Early stopping at epoch 231\n",
      "Early stopping at epoch 597\n",
      "Early stopping at epoch 518\n",
      "Early stopping at epoch 731\n",
      "Early stopping at epoch 442\n",
      "Early stopping at epoch 577\n",
      "Early stopping at epoch 297\n",
      "Early stopping at epoch 509\n",
      "Early stopping at epoch 622\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 409\n",
      "Early stopping at epoch 52\n",
      "Early stopping at epoch 462\n",
      "Early stopping at epoch 433\n",
      "Early stopping at epoch 233\n",
      "Early stopping at epoch 597\n"
     ]
    }
   ],
   "source": [
    "best_result_by_split = {}\n",
    "for carp in range(len(folders)):\n",
    "    torch.cuda.empty_cache()\n",
    "    # Load data\n",
    "    X_train_vec, X_val_vec, X_test_vec, y_train, y_val, y_test = utils.load_data(norm, device, carp, SG=True)\n",
    "    A = pd.read_csv(\"../../step2_graphRepresentation/\"+way_to_build_graph+\"/\"+folders[carp]+\"/graph_Xtr_th_0.975.csv\")\n",
    "    A = torch.tensor(np.array(A), dtype=torch.float32)\n",
    "    \n",
    "        \n",
    "    print(\"X_train_vec:\", X_train_vec.shape)\n",
    "    print(\"X_val_vec:\", X_val_vec.shape)\n",
    "    print(\"X_test_vec:\", X_test_vec.shape)\n",
    "    print(\"y_train:\", y_train.shape)\n",
    "    print(\"y_val:\", y_val.shape)\n",
    "    print(\"y_test:\", y_test.shape)\n",
    "\n",
    "    print(\"===========> TRAIN-VAL PHASE ==================\")\n",
    "    bestHyperparameters = utils.train_val_phase(A, X_train_vec, X_val_vec, y_train, y_val, params, device)\n",
    "    print(\"<========== END TRAIN-VAL PHASE ===============\")\n",
    "    best_result_by_split[folders[carp]] = bestHyperparameters    \n",
    "\n",
    "utils.saveBestHyperparameters(best_result_by_split, \"../hyperparameters/\"+way_to_build_graph+\"/GNN_th_0.975.json\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f002292a",
   "metadata": {},
   "source": [
    "## Validation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa871691",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result_by_split = utils.loadBestHyperparameters(\"../hyperparameters/\"+way_to_build_graph+\"/GNN_th_0.975.json\")\n",
    "\n",
    "typeOfGraph = \"ProdGraph\"\n",
    "path_A = \"graph_Xtr_th_0.975.csv\"\n",
    "results, importance_nodes, fc_classifiers, gnn_models = utils.val_model(best_result_by_split, typeOfGraph, params, folders, \\\n",
    "                                                                        norm, device, path_A, way_to_build_graph, SG=True)\n",
    "\n",
    "keys = list(results.keys())\n",
    "for c in range(len(folders)):\n",
    "    print(\"================= SPLIT \" + str(folders[c]) + \" ===================\")\n",
    "    print(keys[1] + \": \" + str(np.round(results[keys[1]][c]*100,2)))\n",
    "    print(keys[2] + \": \" + str(np.round(results[keys[2]][c]*100,2)))\n",
    "    print(keys[3] + \": \" + str(np.round(results[keys[3]][c]*100,2)))\n",
    "    \n",
    "print()\n",
    "str_result = \"\"\n",
    "filtered_results = {\n",
    "    key: results[key][1:]  \n",
    "    for key in keys\n",
    "}\n",
    "\n",
    "formatted_results = {\"Model\": \"./Results_GCNN\"}\n",
    "\n",
    "column_names = [\"Accuracy\", \"ROC AUC\", \"Sensitivity\", \"Specificity\"]\n",
    "\n",
    "for i, key in enumerate(keys[:4]):  \n",
    "    average = np.mean(filtered_results[key])\n",
    "    std = np.std(filtered_results[key])\n",
    "    formatted_results[column_names[i]] = f\"{np.round(average * 100, 2)} ± {np.round(std * 100, 2)}\"\n",
    "\n",
    "df = pd.DataFrame([formatted_results])\n",
    "\n",
    "\n",
    "output_path = \"../../../Results_GCNN/results.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_path}\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579473cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gnn_models['s1'], './saved_models/s1.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
