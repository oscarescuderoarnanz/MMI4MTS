{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a0f29a-1eee-4388-83af-790b385f9a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 17:40:13.300276: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-10 17:40:13.336667: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-10 17:40:13.337072: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-10 17:40:13.857556: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"../../../libraries/\")\n",
    "import utils\n",
    "\n",
    "sys.path.append(\"../../../classification_architectures/\")\n",
    "import lfco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e943e-6ff6-4398-aa09-088334850ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(split_directory, best_hyperparameters, y_test_pred, y_train_pred=None, model=None):\n",
    "    if not os.path.exists(split_directory):\n",
    "        os.makedirs(split_directory)\n",
    "\n",
    "    with open(os.path.join(split_directory, \"bestHyperparameters.pkl\"), 'wb') as f:\n",
    "        pickle.dump(best_hyperparameters, f)\n",
    "\n",
    "    with open(os.path.join(split_directory, \"y_test_pred.pkl\"), 'wb') as f:\n",
    "        pickle.dump(y_test_pred, f)\n",
    "        \n",
    "    if y_train_pred is not None:\n",
    "        with open(os.path.join(split_directory, \"y_train_pred.pkl\"), 'wb') as f:\n",
    "            pickle.dump(y_test_pred, f)\n",
    "\n",
    "    if model is not None:\n",
    "        model_filename = os.path.join(split_directory, \"model.h5\")\n",
    "        model.save(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d43e25-a113-446f-ad8d-aaa3d915106f",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683684a-8fd3-4807-8bb2-317e16228b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [20, 30, 45, 70]\n",
    "\n",
    "tensor = True\n",
    "debug = True\n",
    "balance = True\n",
    "\n",
    "n_max_num = 5\n",
    "n_categorical_features = 3\n",
    "n_numerical_features = 5\n",
    "n_static_features = n_categorical_features + n_numerical_features\n",
    "n_dynamic_features = 56\n",
    "n_timesteps = 14\n",
    "\n",
    "# Hyperparamas of network\n",
    "epochs = 10000\n",
    "batch_size = 128\n",
    "\n",
    "layers = [3, 5, 8, 10, 15, 20, 25, 30, 35, 40, 50]\n",
    "lr_scheduler = [0.0001, 0.001, 0.01, 0.1]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3]\n",
    "alpha = alpha = np.arange(0, 1, 0.0001)\n",
    "\n",
    "w2 = 0.18\n",
    "w1 = 0.82\n",
    "\n",
    "hyperparameters = {\n",
    "    \"n_categorical_features\": n_categorical_features,\n",
    "    \"n_numerical_features\": n_numerical_features,\n",
    "    \"n_static_features\": n_static_features,\n",
    "    \"n_dynamic_features\": n_dynamic_features,\n",
    "    \"n_timesteps\": n_timesteps,\n",
    "    \"w1\":w1, \"w2\":w2, \n",
    "    \"epochs\":epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'maskValue':666,\n",
    "    'monitor': 'val_loss', \n",
    "    \"mindelta\": 0,\n",
    "    \"patience\":30,\n",
    "    'balance': balance,\n",
    "    'optimizer':'adam',\n",
    "    'kfold':5,\n",
    "    'level':3, \n",
    "    'verbose':0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6520fdab-5d0a-4dec-862a-2bfdffd7ddb7",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e2868-bbed-49db-826d-c19b100639c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v_early = []\n",
    "loss_dev_stat = []\n",
    "loss_dev_dyn = []\n",
    "loss_dev_LFCO = []\n",
    "v_models_stat = []\n",
    "v_models_dyn = []\n",
    "v_models_LFCO = []\n",
    "bestHyperparameters_bySplit_dyn = {}\n",
    "bestHyperparameters_bySplit_stat = {}\n",
    "bestHyperparameters_bySplit_LFCO = {}\n",
    "y_pred_by_split_stat = {}\n",
    "y_pred_by_split_dyn = {}\n",
    "y_pred_by_split_LFCO = {}\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    \n",
    "    path = f'../../../ORIGINAL_DATA/MDR/splits_14_days/notbalanced/split_{str(i)}/'\n",
    "\n",
    "    X_test_dynamic = np.load(path + f\"/X_test_tensor.npy\")\n",
    "    X_test_static = pd.read_csv(path + f\"/X_test_static.csv\", index_col=0)\n",
    "    y_test = pd.read_csv(path + f\"/y_test.csv\", index_col=0)\n",
    "\n",
    "\n",
    "    # DYNAMIC #########################################################################################################\n",
    "    bestHyperparameters_dyn, X_train, y_train, X_train_static, X_val, y_val, X_val_static = lfco.myCVGrid(hyperparameters,\n",
    "                                                                                                 dropout_rate,\n",
    "                                                                                                 lr_scheduler,\n",
    "                                                                                                 layers,\n",
    "                                                                                                 i,                                                              \n",
    "                                                                                                 seeds[i],\n",
    "                                                                                                 path,\n",
    "                                                                                                 model_type=\"dynamic\"\n",
    "                                                                                                 )\n",
    "    bestHyperparameters_bySplit_stat[str(i)] = bestHyperparameters_dyn\n",
    "\n",
    "    hyperparameters.update({\n",
    "        \"dropout_rate\": bestHyperparameters_dyn[\"dropout_rate\"],\n",
    "        \"layers\": bestHyperparameters_dyn[\"layers\"],\n",
    "        \"lr_scheduler\": bestHyperparameters_dyn[\"lr_scheduler\"],\n",
    "    })\n",
    "\n",
    "    utils.reset_keras()\n",
    "    model_dyn, hist, early = lfco.run_network(\n",
    "        X_train, X_train_static, y_train.individualMRGerm.values,\n",
    "        X_val, X_val_static, y_val.individualMRGerm.values,\n",
    "        hyperparameters, seeds[i], model_type=\"dynamic\"\n",
    "    )\n",
    "\n",
    "    #Save the hyperparameters and predictions\n",
    "    split_directory = f'./Results_LFCO/Dynamic/split_{i}'\n",
    "    y_pred_dynamic = model_dyn.predict(X_test_dynamic)\n",
    "    y_train_pred_dynamic = model_dyn.predict(X_train)\n",
    "    \n",
    "    save_results(split_directory, bestHyperparameters_dyn, y_pred_dynamic, y_train_pred_dynamic, model_dyn)\n",
    "\n",
    "    v_models_dyn.append(model_dyn)\n",
    "    loss_dev_dyn.append(hist.history['val_loss'])\n",
    "    y_pred_by_split_dyn[str(i)] = y_pred_dynamic\n",
    "\n",
    "    # STATIC #########################################################################################################\n",
    "    bestHyperparameters_stat, X_train, y_train, X_train_static, X_val, y_val, X_val_static = lfco.myCVGrid(hyperparameters,\n",
    "                                                                                                 dropout_rate,\n",
    "                                                                                                 lr_scheduler,\n",
    "                                                                                                 layers,\n",
    "                                                                                                 i,                                                              \n",
    "                                                                                                 seeds[i],\n",
    "                                                                                                 path,\n",
    "                                                                                                 model_type=\"static\"\n",
    "                                                                                                 )\n",
    "    bestHyperparameters_bySplit_dyn[str(i)] = bestHyperparameters_stat\n",
    "\n",
    "    hyperparameters.update({\n",
    "        \"dropout_rate\": bestHyperparameters_stat[\"dropout_rate\"],\n",
    "        \"layers\": bestHyperparameters_stat[\"layers\"],\n",
    "        \"lr_scheduler\": bestHyperparameters_stat[\"lr_scheduler\"],\n",
    "    })\n",
    "\n",
    "    utils.reset_keras()\n",
    "    model_stat, hist, early = lfco.run_network(\n",
    "        X_train, X_train_static, y_train.individualMRGerm.values,\n",
    "        X_val, X_val_static, y_val.individualMRGerm.values,\n",
    "        hyperparameters, seeds[i], model_type=\"static\"\n",
    "    )\n",
    "\n",
    "    #Save the hyperparameters and predictions\n",
    "    split_directory = f'./Results_LFCO/Static/split_{i}'\n",
    "    y_pred_static = model_stat.predict(X_test_static)\n",
    "    y_train_pred_static = model_stat.predict(X_train_static.values)\n",
    "    \n",
    "    save_results(split_directory, bestHyperparameters_stat, y_pred_static, y_train_pred_static, model_stat)\n",
    "\n",
    "    v_models_stat.append(model_stat)\n",
    "    loss_dev_stat.append(hist.history['val_loss'])\n",
    "    y_pred_by_split_stat[str(i)] = y_pred_dynamic\n",
    "\n",
    "    # LFCO #########################################################################################################\n",
    "    \n",
    "    y_train_summary = y_train.reset_index()\n",
    "    y_train_summary[\"y_pred_static\"] = y_train_pred_static\n",
    "    y_train_summary[\"y_pred_dynamic\"] = y_train_pred_dynamic   \n",
    "    y_test_summary = y_test.reset_index()\n",
    "    y_test_summary[\"y_pred_static\"] = y_pred_static\n",
    "    y_test_summary[\"y_pred_dynamic\"] = y_pred_dynamic\n",
    "\n",
    "    bestHyperparameters_LFCO = lfco.myCVGrid_LFCO(y_train_summary[[\"y_pred_static\", \"y_pred_dynamic\"]], \n",
    "                                                  y_train_summary[[\"individualMRGerm\"]],\n",
    "                                                  alpha,\n",
    "                                                  hyperparameters,\n",
    "                                                  i,\n",
    "                                                  )\n",
    "\n",
    "    bestHyperparameters_bySplit_LFCO[str(i)] = bestHyperparameters_LFCO\n",
    "    best_alpha = bestHyperparameters_LFCO['alpha']\n",
    "    \n",
    "    y_pred = best_alpha * y_test_summary[[\"y_pred_static\"]].values + (1-best_alpha) * y_test_summary[[\"y_pred_dynamic\"]].values\n",
    "\n",
    "    split_directory = f'./Results_LFCO/LR/split_{i}'\n",
    "    save_results(split_directory, bestHyperparameters_LFCO, y_pred)\n",
    "\n",
    "    loss_dev_LFCO.append(hist.history['val_loss'])\n",
    "    y_pred_by_split_LFCO[str(i)] = y_pred\n",
    "\n",
    "    # CALCULATE METRICS ################################################################################################\n",
    "    metrics_dict = utils.calculate_and_save_metrics(\n",
    "    y_test.individualMRGerm.values, \n",
    "    y_pred, \n",
    "    split_directory, \n",
    "    split_index=i\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1436f541-f053-41ba-aea1-65c4e30d1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "hyperparameters = {}\n",
    "hyperparameters['1'] = load_from_pickle(os.path.join('./Results_LFCO/LR/split_1', \"bestHyperparameters.pkl\"))\n",
    "hyperparameters['2'] = load_from_pickle(os.path.join('./Results_LFCO/LR/split_2', \"bestHyperparameters.pkl\"))\n",
    "hyperparameters['3'] = load_from_pickle(os.path.join('./Results_LFCO/LR/split_3', \"bestHyperparameters.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4323ea9f-a3a4-42cd-a970-b4c876a06bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'alpha': 0.8019000000000001},\n",
       " '2': {'alpha': 0.6464000000000001},\n",
       " '3': {'alpha': 0.6214000000000001}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "035e659a-edc0-417f-b9b6-731c7f33278d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.6899000000000001\n",
      "Standard Deviation: 0.07985090272919064\n"
     ]
    }
   ],
   "source": [
    "alpha_values = [hyperparameters['1']['alpha'], hyperparameters['2']['alpha'], hyperparameters['3']['alpha']]\n",
    "\n",
    "# Calculating mean and standard deviation\n",
    "mean_alpha = np.mean(alpha_values)\n",
    "std_alpha = np.std(alpha_values)\n",
    "\n",
    "# Print results\n",
    "print(\"Mean:\", mean_alpha)\n",
    "print(\"Standard Deviation:\", std_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688224e-c2ab-4a8b-b4bd-ec823bd6118f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
