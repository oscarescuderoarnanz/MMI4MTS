{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22e88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0be8a8",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c512c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dynamic_data(df_dynamic, keys, apply_masking, mask_value=666):    \n",
    "    # Convert some features into binary\n",
    "    aux = df_dynamic[keys]\n",
    "    df_dynamic = df_dynamic.drop(columns=keys)\n",
    "    df_dynamic = df_dynamic.astype(bool).astype(int)\n",
    "    df_dynamic = pd.concat([aux, df_dynamic], axis=1)\n",
    "    \n",
    "    # Apply the mask\n",
    "    if apply_masking:\n",
    "        df_dynamic_nomask = df_dynamic[[\"Admissiondboid\", \"dayToDone\", \"individualMRGerm\"]]\n",
    "        df_dynamic_mask = df_dynamic.drop(columns=[\"Admissiondboid\", 'dayToDone', \"individualMRGerm\"])\n",
    "        df_dynamic_mask.at[df_dynamic_mask[\"mask\"] == 0, df_dynamic_mask.keys()] = mask_value\n",
    "        df_dynamic = df_dynamic_nomask.join(df_dynamic_mask)\n",
    "#         df_dynamic = df_dynamic.drop(columns=[\"mask\"])\n",
    "    \n",
    "    return df_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3465731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_static_data(df_static, keys, categorical_keys):\n",
    "    # Eliminate the non-interesting features and get only one sample per patient\n",
    "    df_static = df_static[keys].drop_duplicates()\n",
    "    \n",
    "    # Fill the NaNs\n",
    "    if \"SAPSIIIScore\" in df_static:\n",
    "        df_static[\"SAPSIIIScore\"] = df_static.SAPSIIIScore.fillna(df_static.SAPSIIIScore.mean())\n",
    "\n",
    "    # Reduce the dimensionality of two categorical features\n",
    "    if 'Origin' in df_static:\n",
    "        booleanMapping = (df_static.Origin == \"rehabilitation\") | (df_static.Origin == \"hemodynamics\") | \\\n",
    "        (df_static.Origin == \"cma\") | (df_static.Origin == \"ICU\")  | (df_static.Origin == \"paediatrics\")  | \\\n",
    "        (df_static.Origin == \"obstetrics\")  | (df_static.Origin == \"anaesthesia\")  | (df_static.Origin == \"other floor\") | \\\n",
    "         (df_static.Origin == \"gynaecology\") | (df_static.Origin == \"psychiatry\") | (df_static.Origin == \"dermatology\")\n",
    "        df_static.Origin = df_static.Origin.where(~(booleanMapping), \"others\")\n",
    "    if 'ReasonAdmission' in df_static:\n",
    "        booleanMapping = (df_static.ReasonAdmission == \"endocrine other\") | (df_static.ReasonAdmission == \"coagulopat√≠a\") | \\\n",
    "        (df_static.ReasonAdmission == \"obstetric pathology\") | (df_static.ReasonAdmission == \"infection other\")  | \\\n",
    "        (df_static.ReasonAdmission == \"other\")  | (df_static.ReasonAdmission == \"hydroelectrolytic alteration\")  | \\\n",
    "        (df_static.ReasonAdmission == \"respiratory other\")  | (df_static.ReasonAdmission == \"severe trauma\") | \\\n",
    "         (df_static.ReasonAdmission == \"hepatic insufficiency\") | (df_static.ReasonAdmission == \"diabetic decompensation\") | \\\n",
    "        (df_static.ReasonAdmission == \"neuromuscular\") | (df_static.ReasonAdmission == \"severe arrhythmia\")\n",
    "        df_static.ReasonAdmission = df_static.ReasonAdmission.where(~(booleanMapping), \"others\")\n",
    "    \n",
    "    # Convert the categories of categorical features into numbers\n",
    "    for i in range(len(categorical_keys)):\n",
    "        df_static[categorical_keys[i]] = pd.factorize(df_static[categorical_keys[i]])[0] + 1\n",
    "        \n",
    "    return df_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17285acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_patients(X, ratio=0.7, idPatient='Admissiondboid', seed=42):\n",
    "    \"\"\"\n",
    "    This function split all the samples of the patients in train and test.\n",
    "    \"\"\"\n",
    "    patients = np.array(X[[idPatient]].drop_duplicates())\n",
    "    patients_to_train = pd.DataFrame(data=patients).sample(frac=ratio, random_state=seed).values[:, 0]\n",
    "    X_train = X[X.Admissiondboid.isin(patients_to_train)]\n",
    "    X_test = X[~X.Admissiondboid.isin(patients_to_train)]\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8022ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_standard_scaler(\n",
    "    X_train, X_test,\n",
    "    non_scalable_features,\n",
    "    apply_masking=False, mask_value=666\n",
    "):\n",
    "    \"\"\"\n",
    "    This function implements a standard scaler.\n",
    "    \"\"\"\n",
    "    if apply_masking:\n",
    "        X_train_norm = X_train[X_train[\"mask\"] != mask_value]\n",
    "        X_train_nonorm = X_train[X_train[\"mask\"] == mask_value]\n",
    "        X_test_norm = X_test[X_test[\"mask\"] != mask_value]\n",
    "        X_test_nonorm = X_test[X_test[\"mask\"] == mask_value]\n",
    "    else:\n",
    "        X_train_norm = X_train.copy()\n",
    "        X_test_norm = X_test.copy()\n",
    "    \n",
    "    # Scale in train\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    df_aux = X_train_norm[non_scalable_features]\n",
    "    X_train_norm = X_train_norm.drop(columns=non_scalable_features)\n",
    "    mapper = DataFrameMapper([(X_train_norm.columns, scaler)])\n",
    "    scaled_features = mapper.fit_transform(X_train_norm.copy(), 4)\n",
    "    scaled_X_train = pd.DataFrame(scaled_features, index=X_train_norm.index, columns=X_train_norm.columns)\n",
    "    scaled_X_train = scaled_X_train.join(df_aux)\n",
    "\n",
    "    # Scale in test\n",
    "    df_aux = X_test_norm[non_scalable_features]\n",
    "    X_test_norm = X_test_norm.drop(columns=non_scalable_features)\n",
    "    scaled_features = mapper.transform(X_test_norm.copy())                                        \n",
    "    scaled_X_test = pd.DataFrame(scaled_features, index=X_test_norm.index, columns=X_test_norm.columns)\n",
    "    scaled_X_test = scaled_X_test.join(df_aux)\n",
    "\n",
    "    if apply_masking:\n",
    "        df_final_train = pd.concat([scaled_X_train, X_train_nonorm])\n",
    "        df_final_test = pd.concat([scaled_X_test, X_test_nonorm])\n",
    "        return df_final_train, df_final_test\n",
    "    else:\n",
    "        return scaled_X_train, scaled_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88119f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_tensor(df, y, eliminateColumn, columns, timeStepLength):\n",
    "    _, idx = np.unique(df.Admissiondboid, return_index=True)\n",
    "    listPatients = np.array(df.Admissiondboid)[np.sort(idx)]\n",
    "\n",
    "    index = df.index\n",
    "    y = y.reindex(index)\n",
    "    y = y.drop_duplicates(subset=\"Admissiondboid\")\n",
    "    # y = y.drop(columns=[\"Admissiondboid\"])\n",
    "\n",
    "    for i in range(len(listPatients)):\n",
    "        df_trial = df[df.Admissiondboid == listPatients[i]]\n",
    "        if eliminateColumn:\n",
    "            df_trial = df_trial.drop(columns=columns)\n",
    "        if i == 0:\n",
    "            X = np.array(df_trial)\n",
    "            X = X.reshape(1, timeStepLength, df.shape[1] - len(columns))\n",
    "        else:\n",
    "            X_2 = np.array(df_trial)\n",
    "            X_2 = X_2.reshape(1, timeStepLength, df.shape[1] - len(columns))\n",
    "            X = np.append(X, X_2, axis=0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bcbc692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_static_data(X, y):\n",
    "    X_train_static = pd.merge(X, y.reset_index().Admissiondboid, how=\"right\")\n",
    "    X_train_scaled, _ = my_standard_scaler(\n",
    "        X_train_static, X_train_static, \n",
    "        ['Admissiondboid',  'Origin', 'ReasonAdmission', 'PatientCategory'],\n",
    "        apply_masking=False\n",
    "    )\n",
    "    X_train_scaled = X_train_scaled[[\n",
    "        'Age', 'Gender', 'SAPSIIIScore', 'MonthOfAdmission', 'YearOfAdmission',\n",
    "        'Origin', 'ReasonAdmission', 'PatientCategory'\n",
    "    ]]\n",
    "    return X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3aa715",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ba7cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo = pd.read_csv(\"../../df_dynamic_20days_v10.csv\")\n",
    "df_MR = pd.read_csv(\"../../df_estaticas_v2_covid.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f785f7",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c06931",
   "metadata": {},
   "source": [
    "### Eliminate COVID patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "849fb368",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = np.unique(df_MR[df_MR.COVID != \"zero\"].Admissiondboid)\n",
    "df_completo = df_completo[~df_completo.Admissiondboid.isin(patients)]\n",
    "df_MR = df_MR[~df_MR.Admissiondboid.isin(patients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8a6988c-16aa-46e3-a6c1-281d1727eda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2553\n",
       "1     605\n",
       "Name: individualMRGerm, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_completo[[\"Admissiondboid\", \"individualMRGerm\"]].drop_duplicates().individualMRGerm.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac5e7aa",
   "metadata": {},
   "source": [
    "### Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81a705d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = 14\n",
    "df_windowed = df_completo[df_completo.dayToDone.isin(np.arange(0, n_timesteps, 1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd1a3cb",
   "metadata": {},
   "source": [
    "# Static features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ea2cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\n",
    "    'Admissiondboid', \n",
    "    'Age', 'Gender','Origin', 'ReasonAdmission', 'PatientCategory', \n",
    "    'SAPSIIIScore',            \n",
    "    'MonthOfAdmission', 'YearOfAdmission'\n",
    "       ]\n",
    "categorical_keys = [\"Origin\", \"ReasonAdmission\", \"PatientCategory\"]\n",
    "\n",
    "df_static = load_static_data(df_MR, keys, categorical_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8108eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\n",
    "    'Admissiondboid', 'dayToDone',\n",
    "    'numberOfPatients', 'numberOfPatientsMR',\n",
    "    'neighbor_PAP', 'neighbor_CAR', 'neighbor_Falta', 'neighbor_QUI', 'neighbor_ATF', 'neighbor_GLI', 'neighbor_PEN',\n",
    "    'neighbor_CF3', 'neighbor_CF4', 'neighbor_OXA', 'neighbor_NTI', 'neighbor_LIN', 'neighbor_SUL', 'neighbor_AMG',\n",
    "    'neighbor_CF1', 'neighbor_MAC', 'neighbor_POL', 'neighbor_MON', 'neighbor_GCC', 'neighbor_TTC', 'neighbor_OTR',\n",
    "    'neighbor_LIP', 'neighbor_CF2', 'neighbor_ATI', 'neighbor_IBL', 'neighbor_ATP', \n",
    "    'mask'\n",
    "       ]\n",
    "\n",
    "df_dynamic = load_dynamic_data(df_windowed, keys, apply_masking=True, mask_value=666)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c09463d-18ef-47bd-a257-e399f16f3659",
   "metadata": {},
   "source": [
    "# APPLY THE PERMUTATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dafb66-4e15-40f0-b2a2-e6f0a950f819",
   "metadata": {},
   "source": [
    "**This file will generate the 5 static features for the MLP, as well as the 5 MTS for the GRU model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f0a2dfe-4f56-4d91-a70b-27349b9ea6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SAPSIIIScore', 'Age', 'YearOfAdmission', 'Gender', 'ReasonAdmission']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# APPLY THE PERMUTATION\n",
    "permutation_static = pd.read_csv('../../0_Results_FS_PFI/MLP_selected_features.csv')\n",
    "permutation_static = permutation_static['Selected Feature'].to_list()\n",
    "permutation_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac211694-e60a-45bb-8514-b69d25385642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['isVM', 'PEN', 'neighbor_QUI', 'neighbor_CAR', 'neighbor_SUL']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation = pd.read_csv('../../0_Results_FS_PFI/GRU_selected_features.csv')\n",
    "permutation = permutation['Selected Feature'].to_list()\n",
    "permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19334969-a99b-4fdf-bbd1-718bd3c41259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY THE PERMUTATION\n",
    "df_dynamic = df_dynamic[[\n",
    "    'Admissiondboid', 'dayToDone', \n",
    "    \n",
    "     permutation[0],\n",
    "     permutation[1],\n",
    "     permutation[2],\n",
    "     permutation[3],\n",
    "     permutation[4],\n",
    "    \n",
    "    'mask', \n",
    "    'individualMRGerm'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96bbc696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3158,)\n",
      "(3808,)\n",
      "(3158,)\n",
      "(3158,)\n"
     ]
    }
   ],
   "source": [
    "print(df_dynamic.Admissiondboid.unique().shape)\n",
    "print(df_static.Admissiondboid.unique().shape)\n",
    "\n",
    "df_dynamic = df_dynamic[df_dynamic.Admissiondboid.isin(df_static.Admissiondboid)]\n",
    "df_static = df_static[df_static.Admissiondboid.isin(df_dynamic.Admissiondboid)]\n",
    "\n",
    "print(df_dynamic.Admissiondboid.unique().shape)\n",
    "print(df_static.Admissiondboid.unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acf1f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_scalable_features = ['Admissiondboid', \"dayToDone\", \"individualMRGerm\", \"mask\"]\n",
    "seeds = [142, 56, 78, 97]\n",
    "n_kfold = 5\n",
    "ratio_train_test = 0.8\n",
    "\n",
    "for i in range(len(seeds)):\n",
    "    # Split train and test\n",
    "    X_train, X_test = split_patients(df_dynamic, ratio=ratio_train_test, seed=seeds[i])\n",
    "\n",
    "    # Normalize\n",
    "    X_train_scaled, X_test_scaled = my_standard_scaler(\n",
    "        X_train, X_test, \n",
    "        non_scalable_features,                                               \n",
    "        apply_masking=True\n",
    "    )\n",
    "\n",
    "    # Reorder df for static features\n",
    "    X_train_static = pd.merge(df_static, X_train_scaled.Admissiondboid, how=\"right\")\n",
    "    X_test_static = pd.merge(df_static, X_test_scaled.Admissiondboid, how=\"right\")\n",
    "\n",
    "    # Normalize static features\n",
    "    X_train_static, X_test_static = my_standard_scaler(\n",
    "        X_train_static, X_test_static, \n",
    "        ['Admissiondboid',  'Origin', 'ReasonAdmission', 'PatientCategory'],\n",
    "        apply_masking=False\n",
    "    )\n",
    "\n",
    "    # Execute cross-validation\n",
    "    all_patients_train = np.unique(X_train_scaled.Admissiondboid)\n",
    "    kf = KFold(n_splits=n_kfold, shuffle=True, random_state=seeds[i])\n",
    "    kf.get_n_splits(all_patients_train)\n",
    "    \n",
    "    j = 0\n",
    "    for train_index, val_index in kf.split(np.unique(X_train_scaled.Admissiondboid)):\n",
    "        # Split train into train' and validation\n",
    "        patients_train = all_patients_train[train_index]\n",
    "        patients_val =  all_patients_train[val_index]\n",
    "        X_train_splitted = X_train_scaled[X_train_scaled.Admissiondboid.isin(patients_train)]\n",
    "        X_val_splitted = X_train_scaled[X_train_scaled.Admissiondboid.isin(patients_val)]\n",
    "\n",
    "        # Convert to time tensors\n",
    "        X_train_tensor, y_train = dataframe_to_tensor(\n",
    "            X_train_splitted, X_train_splitted[[\"Admissiondboid\", \"individualMRGerm\"]], \n",
    "            eliminateColumn=True, columns=[\"dayToDone\"], \n",
    "            timeStepLength=n_timesteps\n",
    "        )\n",
    "        X_val_tensor, y_val = dataframe_to_tensor(\n",
    "            X_val_splitted, X_val_splitted[[\"Admissiondboid\", \"individualMRGerm\"]], \n",
    "            eliminateColumn=True, columns=[\"dayToDone\"], \n",
    "            timeStepLength=n_timesteps\n",
    "        )\n",
    "\n",
    "        # Reorder static features and retain a single sample per patient\n",
    "        X_train_static_splitted = pd.merge(X_train_static, y_train.Admissiondboid, how=\"right\")\n",
    "        X_val_static_splitted = pd.merge(X_train_static, y_val.Admissiondboid, how=\"right\")\n",
    "        X_train_static_splitted = X_train_static_splitted.groupby([\"Admissiondboid\"]).mean().reset_index()\n",
    "        X_train_static_splitted = X_train_static_splitted.drop(columns=[\"Admissiondboid\"])\n",
    "        X_val_static_splitted = X_val_static_splitted.groupby([\"Admissiondboid\"]).mean().reset_index()\n",
    "        X_val_static_splitted = X_val_static_splitted.drop(columns=[\"Admissiondboid\"]) \n",
    "\n",
    "        # Eliminate admissiondboid, label, and mask from tensors\n",
    "        X_train_tensor = np.delete(X_train_tensor, [-1, -2, -3], axis=2)\n",
    "        X_val_tensor = np.delete(X_val_tensor, [-1, -2, -3], axis=2)\n",
    "\n",
    "        # Reorder columns of static features\n",
    "        X_train_static_splitted = X_train_static_splitted[[ permutation_static[-5], permutation_static[-4],\n",
    "                                                           permutation_static[-3], permutation_static[-2], permutation_static[-1] ]]\n",
    "        \n",
    "        X_val_static_splitted = X_val_static_splitted[[ permutation_static[-5], permutation_static[-4], \n",
    "                                                       permutation_static[-3], permutation_static[-2], permutation_static[-1] ]]\n",
    "\n",
    "        # Create directories if they do not exist\n",
    "        folder_path = \"../../splits_\" + str(14) + \"_days/PFI_NM/5_features/split_\" + str(i)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "        # Save the data\n",
    "        np.save(folder_path + \"/X_train_tensor_\" + str(j), X_train_tensor)\n",
    "        X_train_static_splitted.to_csv(folder_path + \"/X_train_static_\" + str(j) + \".csv\")\n",
    "        y_train.to_csv(folder_path + \"/y_train_\" + str(j) + \".csv\", index=False)\n",
    "\n",
    "        np.save(folder_path + \"/X_val_tensor_\" + str(j), X_val_tensor)\n",
    "        X_val_static_splitted.to_csv(folder_path + \"/X_val_static_\" + str(j) + \".csv\")\n",
    "        y_val.to_csv(folder_path + \"/y_val_\" + str(j) + \".csv\", index=False)\n",
    "        \n",
    "        j += 1\n",
    "\n",
    "    # Convert test to tensor\n",
    "    X_test_tensor, y_test = dataframe_to_tensor(\n",
    "        X_test_scaled, X_test_scaled[[\"Admissiondboid\", \"individualMRGerm\"]], \n",
    "        eliminateColumn=True, columns=[\"dayToDone\"], \n",
    "        timeStepLength=n_timesteps\n",
    "    )\n",
    "\n",
    "    # Eliminate admissiondboid, label, and mask from test tensor\n",
    "    X_test_tensor = np.delete(X_test_tensor, [-1, -2, -3], axis=2)\n",
    "\n",
    "    # Retain a single sample per patient for static test features\n",
    "    X_test_static = X_test_static.groupby([\"Admissiondboid\"]).mean().reset_index()\n",
    "    X_test_static = X_test_static.drop(columns=[\"Admissiondboid\"])\n",
    "\n",
    "    # Reorder columns of static test features\n",
    "    X_test_static = X_test_static[[ permutation_static[-5], permutation_static[-4], permutation_static[-3], \n",
    "                                   permutation_static[-2], permutation_static[-1] ]]\n",
    "\n",
    "    # Save test data\n",
    "    np.save(folder_path + \"/X_test_tensor\", X_test_tensor)\n",
    "    X_test_static.to_csv(folder_path + \"/X_test_static.csv\")\n",
    "    y_test.to_csv(folder_path + \"/y_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
