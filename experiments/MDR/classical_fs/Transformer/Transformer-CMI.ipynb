{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a3db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "import random, os, json\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Masking, GRU, Dropout, Dense\n",
    "from tensorflow.keras import backend as K\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../../libraries/\")\n",
    "import utils\n",
    "\n",
    "sys.path.append(\"../../../../classification_architectures/\")\n",
    "import transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6736e5d4",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "seeds = [20, 30, 45, 70]\n",
    "results = \"\"\n",
    "debug = True\n",
    "balance = True\n",
    "\n",
    "epochs = 10000\n",
    "batch_size = 128\n",
    "inputShape = 56\n",
    "\n",
    "lr_scheduler = [0.0001, 0.001, 0.01, 0.1]\n",
    "dropout = [0.0, 0.1, 0.2, 0.3]\n",
    "\n",
    "w2 = 0.18\n",
    "w1 = 0.82\n",
    "\n",
    "middle_layer_dim = [3, 5, 8, 10, 15, 20, 25, 30, 35, 40, 50]\n",
    "\n",
    "num_transformer_blocks =  [4, 6]\n",
    "\n",
    "num_heads = [2, 4, 8]\n",
    "\n",
    "epsilon = [0.5, 0.9]\n",
    "\n",
    "\n",
    "\n",
    "hyperparameters = {\n",
    "    \"epochs\":epochs,\n",
    "    \"input_shape\": inputShape,\n",
    "    'batch_size': batch_size,\n",
    "    \"w1\":w1, \"w2\":w2, \n",
    "    'maskValue':666,\n",
    "    'patience':30,\n",
    "    'monitor': 'val_loss', \"mindelta\": 0,\n",
    "    'balance': balance, \"timeStep\": 14,\n",
    "    'optimizer':'adam',\n",
    "    'kfold':5,\n",
    "    'level':3,\n",
    "    'verbose':0\n",
    "}\n",
    "\n",
    "tensor = True\n",
    "tab = \"\\t\" * hyperparameters[\"level\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0596817d",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec65fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model = False\n",
    "\n",
    "if run_model:\n",
    "    v_early = []\n",
    "    loss_dev = []\n",
    "    v_models = []\n",
    "    bestHyperparameters_bySplit = {}\n",
    "    y_pred_by_split = {}\n",
    "\n",
    "    for i in range(1, 4):\n",
    "        path = f'../../../../ORIGINAL_DATA/MDR/splits_14_days/majority/split_{str(i)}/'\n",
    "    \n",
    "        X_test = np.load(path + f\"/X_test_tensor.npy\")\n",
    "        y_test = pd.read_csv(path + f\"/y_test.csv\", index_col=0)\n",
    "    \n",
    "        bestHyperparameters, X_train, y_train, X_val, y_val = transformer.myCVGrid(hyperparameters,\n",
    "                                                                                   dropout, \n",
    "                                                                                   lr_scheduler, \n",
    "                                                                                   middle_layer_dim, \n",
    "                                                                                   num_transformer_blocks,\n",
    "                                                                                   num_heads, \n",
    "                                                                                   epsilon,\n",
    "                                                                                   i,                                                              \n",
    "                                                                                   seeds[i],\n",
    "                                                                                   path\n",
    "                                                                                  )\n",
    "        bestHyperparameters_bySplit[str(i)] = bestHyperparameters\n",
    "    \n",
    "        # Save best hyperparameters for current split\n",
    "        split_directory = './Results_Transformer-CMI/split_' + str(i)\n",
    "        if not os.path.exists(split_directory):\n",
    "            os.makedirs(split_directory)\n",
    "    \n",
    "        with open(os.path.join(split_directory, f\"bestHyperparameters_split_{i}.pkl\"), 'wb') as f:\n",
    "            pickle.dump(bestHyperparameters, f)\n",
    "    \n",
    "    \n",
    "        hyperparameters = {\n",
    "            \"w1\":hyperparameters[\"w1\"], \"w2\":hyperparameters[\"w2\"],                                    \n",
    "            \"timeStep\": hyperparameters[\"timeStep\"],\n",
    "            'epochs':  hyperparameters[\"epochs\"],\n",
    "            'batch_size': hyperparameters[\"batch_size\"],\n",
    "            'maskValue': hyperparameters[\"maskValue\"],\n",
    "            \"input_shape\": hyperparameters[\"input_shape\"],\n",
    "            'earlyStopping': True,\n",
    "            'kfold': hyperparameters[\"kfold\"],\n",
    "            'monitor': hyperparameters[\"monitor\"],\n",
    "            \"mindelta\": hyperparameters[\"mindelta\"],\n",
    "            \"patience\": hyperparameters[\"patience\"],\n",
    "            'balance': hyperparameters[\"balance\"],\n",
    "            \"dropout\": bestHyperparameters[\"dropout\"],\n",
    "            \"lr_scheduler\": bestHyperparameters[\"lr_scheduler\"],\n",
    "            \"level\": 3, 'verbose': 0,\n",
    "\n",
    "            'middle_layer_dim': bestHyperparameters['middle_layer_dim'],\n",
    "            'num_transformer_blocks': bestHyperparameters['num_transformer_blocks'],\n",
    "            'num_heads': bestHyperparameters['num_heads'],\n",
    "            'epsilon': bestHyperparameters['epsilon'],\n",
    "        }\n",
    "    \n",
    "        #Try on test\n",
    "        utils.reset_keras()\n",
    "\n",
    "        model, hist, early = transformer.run_network(\n",
    "            X_train, y_train.individualMRGerm.values,\n",
    "            X_val, y_val.individualMRGerm.values,\n",
    "            hyperparameters, \n",
    "            seeds[i]\n",
    "        )    \n",
    "    \n",
    "        v_models.append(model)\n",
    "        loss_dev.append(hist.history['val_loss'])\n",
    "    \n",
    "        y_pred = model.predict(x=[X_test])\n",
    "        y_pred_by_split[str(i)] = y_pred\n",
    "        \n",
    "        with open(os.path.join(split_directory, f\"y_pred_split_{i}.pkl\"), 'wb') as f:\n",
    "            pickle.dump(y_pred, f)\n",
    "    \n",
    "        # Save model for current split\n",
    "        model_filename = os.path.join(split_directory, f\"model_split_{i}.h5\")\n",
    "        model.save(model_filename)\n",
    "    \n",
    "        # Calculate metrics\n",
    "        metrics_dict = utils.calculate_and_save_metrics(\n",
    "        y_test.individualMRGerm.values, \n",
    "        y_pred, \n",
    "        split_directory, \n",
    "        split_index=i\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39328e5-35d2-4997-bb4e-306a0cfde13f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
